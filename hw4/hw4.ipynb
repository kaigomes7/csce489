{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(os.getcwd() + '\\\\data') for f in filenames]\n",
    "data_titles = [text[text.index('data')+5:].replace('\\\\', '/') for text in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(input='filename', decode_error='ignore')\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_vector.astype('float32').toarray().astype('float16'), index=data_titles, columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "br             0.450195\n",
       "nbsp           0.256348\n",
       "idris          0.247681\n",
       "abass          0.247681\n",
       "my             0.245361\n",
       "yakubu         0.178345\n",
       "the            0.174438\n",
       "handicapped    0.140503\n",
       "of             0.124329\n",
       "beign          0.123840\n",
       "eessth         0.123840\n",
       "less           0.118225\n",
       "wealth         0.116943\n",
       "privileged     0.107849\n",
       "and            0.106323\n",
       "vanity         0.103149\n",
       "god            0.100586\n",
       "am             0.092346\n",
       "to             0.091492\n",
       "quot           0.087952\n",
       "in             0.087952\n",
       "live           0.084229\n",
       "personal       0.083252\n",
       "for            0.082886\n",
       "joy            0.081055\n",
       "Name: GP/part6/msg9150.eml, dtype: float16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.T['GP/part6/msg9150.eml'].sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enron          0.531250\n",
       "skygen         0.334473\n",
       "calpine        0.305908\n",
       "com            0.276611\n",
       "panda          0.161865\n",
       "mw             0.142090\n",
       "the            0.116699\n",
       "michael        0.115112\n",
       "of             0.103333\n",
       "alliance       0.101501\n",
       "oneta          0.100342\n",
       "energy         0.094666\n",
       "development    0.084656\n",
       "turbines       0.084229\n",
       "polsky         0.083618\n",
       "steve          0.079102\n",
       "projects       0.071899\n",
       "under          0.069885\n",
       "will           0.069763\n",
       "and            0.067017\n",
       "larry          0.063477\n",
       "john           0.063110\n",
       "ken            0.061157\n",
       "frank          0.059631\n",
       "gas            0.058014\n",
       "Name: lokay-m/articles/1, dtype: float16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.T['lokay-m/articles/1'].sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df['Spam'] = [1 if re.match('GP\\/part[0-9]*\\/.*\\.eml', filename) else 0 for filename in data_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_df.filter(regex='(GP\\/part[0-9]\\/.*\\.eml)|(kitchen-l\\/.*)', axis=0)\n",
    "y_train = X_train['Spam']\n",
    "X_train = X_train.drop('Spam', axis = 1)\n",
    "X_test = tfidf_df.filter(regex='(GP\\/part[0-9][0-9]\\/.*\\.eml)|(lokay-m\\/.*)', axis=0)\n",
    "y_test = X_test['Spam']\n",
    "X_test = X_test.drop('Spam', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_jobs=20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=100, n_jobs=20, max_depth=10)\n",
    "rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score:     0.9993087955762917\n",
      "True positive:   3423\n",
      "False positive:  4\n",
      "True negative:   2360\n",
      "False negative:  0\n"
     ]
    }
   ],
   "source": [
    "y_fit = rfc_model.predict(X_test)\n",
    "cfm = confusion_matrix(y_test, y_fit)\n",
    "print(f\"Model score:     {rfc_model.score(X_test, y_test)}\")\n",
    "print(f'True positive:   {cfm[1][1]}')\n",
    "print(f'False positive:  {cfm[0][1]}')\n",
    "print(f'True negative:   {cfm[0][0]}')\n",
    "print(f'False negative:  {cfm[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 3080: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11932\\1256435177.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stop_words.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstop_words_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\env1\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 3080: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "with open('stop_words.txt', encoding=\"utf8\") as stop_words_file:\n",
    "    stop_words_list = stop_words_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(input='filename', decode_error='ignore', stop_words='')\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(data_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad511ddb7bc7263d1c1429069e77735e79ca43f39e7398984826b812170d9ec0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
